{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6aaaf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "from diffusion_planner.model.diffusion_planner import Diffusion_Planner\n",
    "from diffusion_planner.utils.normalizer import StateNormalizer\n",
    "from diffusion_planner.model.diffusion_planner import OnnxWrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85066fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从JSON加载的原始配置 (args.state_normalizer 类型): <class 'dict'>\n",
      "正在将 state_normalizer 从字典转换为实例对象...\n",
      "修正完成! 当前 config.state_normalizer 类型: <class 'diffusion_planner.utils.normalizer.StateNormalizer'>\n",
      "正在初始化 Diffusion_Planner 模型...\n",
      "模型初始化完成!\n"
     ]
    }
   ],
   "source": [
    "# --- 您的代码：加载配置（这部分是正确的）---\n",
    "current_directory = os.getcwd()\n",
    "path = os.path.join(current_directory, \"checkpoints\", \"args.json\")\n",
    "\n",
    "# 1. 加载JSON文件\n",
    "with open(path, 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# 2. 将字典转换为Namespace对象\n",
    "args = argparse.Namespace(**config_dict)\n",
    "args.guidance_fn = None\n",
    "print(\"从JSON加载的原始配置 (args.state_normalizer 类型):\", type(args.state_normalizer))\n",
    "\n",
    "\n",
    "# --- 关键修正步骤：手动实例化对象 ---\n",
    "# 检查 state_normalizer 是否是一个需要被实例化的字典\n",
    "if hasattr(args, 'state_normalizer') and isinstance(args.state_normalizer, dict):\n",
    "    print(\"正在将 state_normalizer 从字典转换为实例对象...\")\n",
    "    # 从字典中解包参数来创建对象\n",
    "    normalizer_params = args.state_normalizer\n",
    "    state_normalizer_object = StateNormalizer(**normalizer_params)\n",
    "    \n",
    "    # 将 args 中的字典替换为真正的实例对象\n",
    "    args.state_normalizer = state_normalizer_object\n",
    "    print(\"修正完成! 当前 config.state_normalizer 类型:\", type(args.state_normalizer))\n",
    "# --- 修正结束 ---\n",
    "\n",
    "# --- 现在，使用修正后的 args 初始化模型 ---\n",
    "print(\"正在初始化 Diffusion_Planner 模型...\")\n",
    "model = Diffusion_Planner(args)\n",
    "print(\"模型初始化完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0650b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从 ./checkpoints/model.pth 加载权重...\n",
      "权重已成功加载！\n"
     ]
    }
   ],
   "source": [
    "# 导入 OrderedDict\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 1. 加载检查点文件\n",
    "checkpoint_path = \"./checkpoints/model.pth\"\n",
    "print(f\"正在从 {checkpoint_path} 加载权重...\")\n",
    "original_state_dict = torch.load(checkpoint_path, map_location='cpu')['model']\n",
    "\n",
    "# 2. 只处理 'module.' 前缀 (如果需要)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in original_state_dict.items():\n",
    "    name = k[7:] if k.startswith('module.') else k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "# 3. 直接加载，不再需要重命名 'in_proj_weight'\n",
    "model.load_state_dict(new_state_dict)\n",
    "print(\"权重已成功加载！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdab857b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已设置为评估模式并已包装。\n"
     ]
    }
   ],
   "source": [
    "# --- 2d. 设置评估模式并包装模型 ---\n",
    "model.eval()\n",
    "wrapped_model = OnnxWrapper(model)\n",
    "wrapped_model.eval()\n",
    "print(\"模型已设置为评估模式并已包装。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566452b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 步骤 3: 准备导出参数 ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 步骤 3: 准备导出所需的“三件套”\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 3: 准备导出参数 ---\")\n",
    "\n",
    "# --- 3a. 伪输入元组 (Dummy Inputs) ---\n",
    "dummy_neighbor_agents_past = torch.randn(1, 32, 21, 11)\n",
    "dummy_ego_current_state = torch.randn(1, 10)\n",
    "dummy_static_objects = torch.randn(1, 5, 10)\n",
    "dummy_lanes = torch.randn(1, 70, 20, 12)\n",
    "dummy_lanes_speed_limit = torch.randn(1, 70, 1)\n",
    "dummy_lanes_has_speed_limit = torch.ones(1, 70, 1).bool() # 已修正\n",
    "dummy_route_lanes = torch.randn(1, 25, 20, 12)\n",
    "dummy_route_lanes_speed_limit = torch.randn(1, 25, 1)\n",
    "dummy_route_lanes_has_speed_limit = torch.ones(1, 25, 1).bool() # 已修正\n",
    "\n",
    "dummy_inputs_tuple = (\n",
    "    dummy_neighbor_agents_past, dummy_ego_current_state, dummy_static_objects,\n",
    "    dummy_lanes, dummy_lanes_speed_limit, dummy_lanes_has_speed_limit,\n",
    "    dummy_route_lanes, dummy_route_lanes_speed_limit, dummy_route_lanes_has_speed_limit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd26767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "导出参数准备就绪。\n"
     ]
    }
   ],
   "source": [
    "# --- 3b. 输入输出节点名称 ---\n",
    "input_names = [\n",
    "    \"neighbor_agents_past\", \"ego_current_state\", \"static_objects\", \"lanes\",\n",
    "    \"lanes_speed_limit\", \"lanes_has_speed_limit\", \"route_lanes\",\n",
    "    \"route_lanes_speed_limit\", \"route_lanes_has_speed_limit\",\n",
    "]\n",
    "# 推理时模型返回 {\"prediction\": x0}，所以输出节点名为 \"prediction\"\n",
    "output_names = [\"prediction\"] \n",
    "\n",
    "# --- 3c. 动态轴 ---\n",
    "dynamic_axes = {name: {0: \"batch_size\"} for name in input_names}\n",
    "dynamic_axes[output_names[0]] = {0: \"batch_size\"}\n",
    "print(\"导出参数准备就绪。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ab5585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 步骤 4: 执行导出与验证 ---\n",
      "即将导出 ONNX 模型到: diffusion_planner.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/module/encoder.py:176: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if valid_indices.sum() > 0:\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/module/encoder.py:249: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if has_speed_limit.sum() > 0:\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/module/encoder.py:253: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (~has_speed_limit).sum() > 0:\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/module/custom_multihead_attention.py:43: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert T_k == T_v, \"Key and Value must have the same sequence length\"\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/module/custom_multihead_attention.py:95: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(D_h)\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/module/custom_multihead_attention.py:104: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert key_padding_mask.shape == (B, T_k), f\"Expected key_padding_mask shape ({B}, {T_k}), got {key_padding_mask.shape}\"\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/module/decoder.py:84: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert P == (1 + self._predicted_neighbor_num)\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/diffusion_utils/dpm_solver_pytorch.py:469: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  lambda_T = self.noise_schedule.marginal_lambda(torch.tensor(t_T).to(device))\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/diffusion_utils/dpm_solver_pytorch.py:470: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  lambda_0 = self.noise_schedule.marginal_lambda(torch.tensor(t_0).to(device))\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/diffusion_utils/dpm_solver_pytorch.py:471: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  logSNR_steps = torch.linspace(lambda_T.cpu().item(), lambda_0.cpu().item(), N + 1).to(device)\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/diffusion_utils/dpm_solver_pytorch.py:1174: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert timesteps.shape[0] - 1 == steps\n",
      "/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner/model/module/custom_multihead_attention.py:48: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if is_self_attention:\n",
      "/home/bydguikong/anaconda3/envs/diffusion_planner/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:2112: FutureWarning: 'torch.onnx.symbolic_opset9._cast_Bool' is deprecated in version 2.0 and will be removed in the future. Please Avoid using this function and create a Cast node instead.\n",
      "  return fn(g, to_cast_func(g, input, False), to_cast_func(g, other, False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "\n",
      "✅ ONNX 模型导出成功!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 步骤 4: 执行导出并验证\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 4: 执行导出与验证 ---\")\n",
    "onnx_filename = \"diffusion_planner.onnx\"\n",
    "print(f\"即将导出 ONNX 模型到: {onnx_filename}\")\n",
    "\n",
    "try:\n",
    "    torch.onnx.export(\n",
    "        wrapped_model,\n",
    "        dummy_inputs_tuple,\n",
    "        onnx_filename,\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "        dynamic_axes=dynamic_axes,\n",
    "        opset_version=11,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(f\"\\n✅ ONNX 模型导出成功!\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 导出过程中发生错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af0c357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在验证导出的 ONNX 模型...\n",
      "   - ONNX 模型实际有 7 个输入: ['neighbor_agents_past', 'ego_current_state', 'static_objects', 'lanes', 'lanes_speed_limit', 'lanes_has_speed_limit', 'route_lanes']\n",
      "✅ ONNX 模型验证成功!\n",
      "   - ONNX Runtime 推理输出数量: 1\n",
      "   - ONNX 输出节点名称: ['prediction']\n",
      "   - 第一个输出 'prediction' 的形状: (1, 11, 80, 4)\n"
     ]
    }
   ],
   "source": [
    "# --- （强烈推荐）步骤4：验证导出的模型 (已修正) ---\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n正在验证导出的 ONNX 模型...\")\n",
    "\n",
    "# 1. 创建 ONNX Runtime 推理会话\n",
    "ort_session = onnxruntime.InferenceSession(onnx_filename)\n",
    "\n",
    "# 2. 准备一个从输入名到伪输入张量的查找字典\n",
    "#    (input_names 和 dummy_inputs_tuple 是我们之前定义的)\n",
    "dummy_inputs_by_name = dict(zip(input_names, dummy_inputs_tuple))\n",
    "\n",
    "# 3. 获取 ONNX 模型真正需要的输入节点的名称\n",
    "actual_input_names = [inp.name for inp in ort_session.get_inputs()]\n",
    "print(f\"   - ONNX 模型实际有 {len(actual_input_names)} 个输入: {actual_input_names}\")\n",
    "\n",
    "# 辅助函数，将 torch tensor 转为 numpy array\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# 4. 根据模型实际需要的输入，来构建 onnxruntime 的输入字典\n",
    "ort_inputs = {\n",
    "    name: to_numpy(dummy_inputs_by_name[name])\n",
    "    for name in actual_input_names\n",
    "}\n",
    "\n",
    "# 5. 执行推理\n",
    "ort_outputs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# 6. 打印结果，检查形状\n",
    "print(\"✅ ONNX 模型验证成功!\")\n",
    "print(f\"   - ONNX Runtime 推理输出数量: {len(ort_outputs)}\")\n",
    "# 假设您的 Encoder 输出是一个字典，其中包含一个名为 'encoding' 的键\n",
    "# ONNX 导出后，这个键名会成为输出节点名\n",
    "output_node_names = [out.name for out in ort_session.get_outputs()]\n",
    "print(f\"   - ONNX 输出节点名称: {output_node_names}\")\n",
    "print(f\"   - 第一个输出 '{output_node_names[0]}' 的形状: {ort_outputs[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff8bf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mYour model contains \"Tile\" ops or/and \"ConstantOfShape\" ops. Folding these ops \u001b[0m\n",
      "\u001b[1;35mcan make the simplified model much larger. If it is not expected, please specify\u001b[0m\n",
      "\u001b[1;35m\"--no-large-tensor\" (which will lose some optimization chances)\u001b[0m\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add              │ 1351           │ \u001b[1;32m1338            \u001b[0m │\n",
      "│ And              │ 74             │ 74               │\n",
      "│ Atan             │ 1              │ 1                │\n",
      "│ Cast             │ 356            │ \u001b[1;32m82              \u001b[0m │\n",
      "│ Concat           │ 486            │ \u001b[1;32m302             \u001b[0m │\n",
      "│ Constant         │ 3909           │ \u001b[1;32m440             \u001b[0m │\n",
      "│ ConstantOfShape  │ 165            │ \u001b[1;32m26              \u001b[0m │\n",
      "│ Cos              │ 12             │ 12               │\n",
      "│ Div              │ 396            │ 396              │\n",
      "│ Equal            │ 146            │ \u001b[1;32m80              \u001b[0m │\n",
      "│ Erf              │ 38             │ 38               │\n",
      "│ Exp              │ 22             │ 22               │\n",
      "│ Expand           │ 177            │ \u001b[1;32m167             \u001b[0m │\n",
      "│ Gather           │ 463            │ \u001b[1;32m420             \u001b[0m │\n",
      "│ GatherND         │ 10             │ 10               │\n",
      "│ Gemm             │ 78             │ 78               │\n",
      "│ Greater          │ 36             │ 36               │\n",
      "│ Identity         │ 282            │ \u001b[1;32m0               \u001b[0m │\n",
      "│ If               │ 2              │ \u001b[1;32m0               \u001b[0m │\n",
      "│ IsInf            │ 72             │ 72               │\n",
      "│ IsNaN            │ 36             │ 36               │\n",
      "│ Less             │ 40             │ \u001b[1;32m38              \u001b[0m │\n",
      "│ MatMul           │ 510            │ 510              │\n",
      "│ Mul              │ 1473           │ \u001b[1;32m1266            \u001b[0m │\n",
      "│ NonZero          │ 26             │ \u001b[1;32m12              \u001b[0m │\n",
      "│ Not              │ 16             │ \u001b[1;32m15              \u001b[0m │\n",
      "│ Pow              │ 200            │ 200              │\n",
      "│ RandomNormalLike │ 1              │ 1                │\n",
      "│ Range            │ 78             │ \u001b[1;32m67              \u001b[0m │\n",
      "│ ReduceMean       │ 381            │ 381              │\n",
      "│ ReduceSum        │ 9              │ 9                │\n",
      "│ Reshape          │ 472            │ \u001b[1;32m407             \u001b[0m │\n",
      "│ ScatterND        │ 48             │ \u001b[1;32m38              \u001b[0m │\n",
      "│ Shape            │ 684            │ \u001b[1;32m279             \u001b[0m │\n",
      "│ Sigmoid          │ 22             │ 22               │\n",
      "│ Sin              │ 12             │ 12               │\n",
      "│ Slice            │ 412            │ \u001b[1;32m379             \u001b[0m │\n",
      "│ Softmax          │ 69             │ 69               │\n",
      "│ Sqrt             │ 200            │ 200              │\n",
      "│ Squeeze          │ 2              │ 2                │\n",
      "│ Sub              │ 273            │ 273              │\n",
      "│ Tanh             │ 77             │ 77               │\n",
      "│ Transpose        │ 322            │ \u001b[1;32m308             \u001b[0m │\n",
      "│ Unsqueeze        │ 1290           │ \u001b[1;32m646             \u001b[0m │\n",
      "│ Where            │ 276            │ \u001b[1;32m212             \u001b[0m │\n",
      "│ Model Size       │ 26.0MiB        │ \u001b[1;32m25.6MiB         \u001b[0m │\n",
      "└──────────────────┴────────────────┴──────────────────┘\n"
     ]
    }
   ],
   "source": [
    "!python -m onnxsim ./diffusion_planner.onnx ./simplified_model.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d025b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving '/home/bydguikong/yy_ws/Diffusion-Planner/diffusion_planner.onnx' at http://localhost:8080\n",
      "Serving '/home/bydguikong/yy_ws/Diffusion-Planner/simplified_model.onnx' at http://localhost:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8081)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netron\n",
    "current_directory = os.getcwd()\n",
    "netron.start(current_directory + \"/diffusion_planner.onnx\")\n",
    "netron.start(current_directory + \"/simplified_model.onnx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_planner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
